{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf8d058-5442-4b04-825c-8231b3b8741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "from numpy.linalg import norm, svd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Figures \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.transforms\n",
    "import matplotlib.ticker\n",
    "from style import colors\n",
    "from fig_specs import *\n",
    "\n",
    "from helpers import comp_pr, plot_samples\n",
    "\n",
    "from data_loaders import (\n",
    "    load_golub_2018, load_hennig_2018, load_degenhart_2020, load_russo_2018, load_nlb_maze, load_nlb_rtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62bd943-97b0-4501-bfdd-077b81a19442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_corr(X, w_out):\n",
    "    \"\"\" Correlation between states and output weights.\n",
    "    With population average at each time point subtracted.\n",
    "    \"\"\"\n",
    "    return norm(X @ w_out.T) / (norm(X) * norm(w_out))\n",
    "\n",
    "def comp_ridge(hids, output, d_thr=0.9):\n",
    "    X = hids.astype(float)\n",
    "    y = output\n",
    "    # Center along time\n",
    "    X = X - X.mean(0)\n",
    "    y = y - y.mean(0)\n",
    "    \n",
    "    n_samples, dim_hid = X.shape\n",
    "    alpha_range = np.logspace(-3, 6, 20)\n",
    "    ridge = RidgeCV(alphas=alpha_range)\n",
    "    ridge.fit(X, y)\n",
    "    r_sq = ridge.score(X, y)\n",
    "    ridge_alpha = ridge.alpha_\n",
    "    # Output weights\n",
    "    w_out = ridge.coef_\n",
    "    \n",
    "    # Correlation between output weights and hidden states\n",
    "    corr_w_x = comp_corr(X, w_out)\n",
    "    \n",
    "    # Participation ratio\n",
    "    pr = comp_pr(X)\n",
    "    \n",
    "    # Compute dimensions of data and necessary to fit\n",
    "    d_var, d_var_rel, d_fit_rel, d_fits, r_sq_ps = comp_dim_var_fit(X, y, ridge, d_thr)\n",
    "    # Ratio between relative dimensions\n",
    "    ratio_d_fit_var_rel = d_fit_rel / d_var_rel\n",
    "    \n",
    "    res = {\n",
    "        \"r_sq\": r_sq, \n",
    "        \"ridge_alpha\": ridge_alpha, \n",
    "        \"corr_w_x\": corr_w_x, \n",
    "        \"pr\": pr, \n",
    "        \"n_samples\": n_samples, \n",
    "        \"dim_hid\": dim_hid, \n",
    "        \"d_var\": d_var, \n",
    "        \"d_var_rel\": d_var_rel, \n",
    "        \"d_fit_rel\": d_fit_rel, \n",
    "        \"ratio_d_fit_var_rel\": ratio_d_fit_var_rel,\n",
    "        \"w_out\": w_out,\n",
    "    }\n",
    "    \n",
    "    ### Fits on subsets\n",
    "    lbls_res_t = [\"r_sq\", \"ridge_alpha\", \"corr_w_x\", \"pr\", \n",
    "        \"d_var\", \"d_var_rel\", \"d_fit_rel\", \"ratio_d_fit_var_rel\", \n",
    "               ]\n",
    "    # Fit on subsamples in time points\n",
    "    n_fit_t = 20\n",
    "    frac_n_t = 1/4\n",
    "    n_subs_t = int(n_samples * frac_n_t)\n",
    "    # Results\n",
    "    res_subs_t = np.zeros((len(lbls_res_t), n_fit_t))\n",
    "    for i_fit in tqdm(range(n_fit_t)):\n",
    "        idx_s = rng.choice(n_samples, n_subs_t, replace=False)\n",
    "        X_s, y_s = X[idx_s], y[idx_s]\n",
    "        ridge.fit(X_s, y_s)\n",
    "        w_out_s = ridge.coef_\n",
    "        res_subs_t[0, i_fit] = ridge.score(X_s, y_s)\n",
    "        res_subs_t[1, i_fit] = ridge.alpha_\n",
    "        res_subs_t[2, i_fit] = comp_corr(X_s, w_out_s)\n",
    "        res_subs_t[3, i_fit] = comp_pr(X_s)\n",
    "        \n",
    "        # Compute dimensions of data and necessary to fit\n",
    "        d_var, d_var_rel, d_fit_rel, d_fits, r_sq_ps = comp_dim_var_fit(X_s, y_s, ridge, d_thr)\n",
    "        ratio_d_fit_var_rel = d_fit_rel / d_var_rel\n",
    "        res_subs_t[4:8, i_fit] = d_var, d_var_rel, d_fit_rel, ratio_d_fit_var_rel,\n",
    "    # Save as dict\n",
    "    res_subs_t = {lbls_res_t[i]: res_sub for i, res_sub in enumerate(res_subs_t)}\n",
    "    \n",
    "    # Fit on subsets of neurons\n",
    "    # Number of subsets\n",
    "    n_fit_n = 20\n",
    "    # Number of neurons\n",
    "    frac_dim_hids = np.linspace(0.1, 1., 10)\n",
    "    dim_hid_subs = np.int_(dim_hid * frac_dim_hids)\n",
    "    n_dim_hid = len(dim_hid_subs)\n",
    "    # Results\n",
    "    lbls_res_n = [\"r_sq\", \"ridge_alpha\", \"corr_w_x\", \"pr\",\n",
    "               ]\n",
    "    res_subs_n = np.zeros((len(lbls_res_n), n_fit_n, n_dim_hid))\n",
    "    for i_fit in tqdm(range(n_fit_n)):\n",
    "        for i_n in range(n_dim_hid):\n",
    "            dim_hid_i = dim_hid_subs[i_n]\n",
    "            idx_n = rng.choice(dim_hid, dim_hid_i, replace=False)\n",
    "            X_n = X[:, idx_n]\n",
    "            ridge.fit(X_n, y)\n",
    "            w_out_s = ridge.coef_\n",
    "            res_subs_n[0, i_fit, i_n] = ridge.score(X_n, y)\n",
    "            res_subs_n[1, i_fit, i_n] = ridge.alpha_\n",
    "            res_subs_n[2, i_fit, i_n] = comp_corr(X_n, w_out_s)\n",
    "            res_subs_n[3, i_fit, i_n] = comp_pr(X_n)\n",
    "\n",
    "    # Save as dict\n",
    "    res_subs_n = {lbls_res_n[i]: res_sub for i, res_sub in enumerate(res_subs_n)}\n",
    "\n",
    "    return res, res_subs_t, res_subs_n\n",
    "\n",
    "def comp_dim_var_fit(X_i, y_i, ridge, d_thr):\n",
    "    # Compare variance explained with the ability to fit based on the leading components\n",
    "    dim_hid = X_i.shape[1]\n",
    "\n",
    "    # Use SVD instead of PCA (adds one mode)\n",
    "    U, S, _ = svd(X_i.T, full_matrices=False)\n",
    "    # Dimension of data\n",
    "    cevr = (S**2).cumsum() / (S**2).sum()\n",
    "    i_thr = np.where(cevr > d_thr)[0]\n",
    "    d_var = i_thr[0] + 1\n",
    "    \n",
    "    # Fit on full dataset first\n",
    "    ridge.fit(X_i, y_i)\n",
    "    r_sq_full = ridge.score(X_i, y_i)\n",
    "    \n",
    "    # Where does the cevr reach the same as 90% of the highest R^2?\n",
    "    i_thr = np.where(cevr > r_sq_full * d_thr)[0]\n",
    "    d_var_rel = i_thr[0] + 1\n",
    "    \n",
    "    # Fit for a small number of dimensions\n",
    "    d_fits = []\n",
    "    r_sq_ps = []\n",
    "    d_fit = 0\n",
    "    while True:\n",
    "        d_fit += 1\n",
    "        if d_fit > dim_hid:\n",
    "            break\n",
    "        # Projection of X onto leading modes\n",
    "        X_ip = X_i @ U[:, :d_fit]\n",
    "        # Fit the output based on the projection\n",
    "        ridge.fit(X_ip, y_i)\n",
    "        r_sq_p = ridge.score(X_ip, y_i)\n",
    "        d_fits.append(d_fit)\n",
    "        r_sq_ps.append(r_sq_p)\n",
    "        if r_sq_p > r_sq_full * d_thr:\n",
    "            d_fit_rel = d_fit\n",
    "            break\n",
    "\n",
    "    return d_var, d_var_rel, d_fit_rel, d_fits, r_sq_ps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437e04e3-9d18-4dce-a1d7-c2b49c7c2e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci-golub_2018-before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▏                                            | 7/20 [00:01<00:03,  3.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         output \u001b[38;5;241m=\u001b[39m output_dict[key]\n\u001b[1;32m     39\u001b[0m         hids \u001b[38;5;241m=\u001b[39m hids_dict[key]\n\u001b[0;32m---> 40\u001b[0m         results[ds_name] \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_ridge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegenhart_2020\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     42\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mcomp_ridge\u001b[0;34m(hids, output, d_thr)\u001b[0m\n\u001b[1;32m     66\u001b[0m res_subs_t[\u001b[38;5;241m3\u001b[39m, i_fit] \u001b[38;5;241m=\u001b[39m comp_pr(X_s)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Compute dimensions of data and necessary to fit\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m d_var, d_var_rel, d_fit_rel, d_fits, r_sq_ps \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_dim_var_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mridge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_thr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m ratio_d_fit_var_rel \u001b[38;5;241m=\u001b[39m d_fit_rel \u001b[38;5;241m/\u001b[39m d_var_rel\n\u001b[1;32m     71\u001b[0m res_subs_t[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m8\u001b[39m, i_fit] \u001b[38;5;241m=\u001b[39m d_var, d_var_rel, d_fit_rel, ratio_d_fit_var_rel,\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mcomp_dim_var_fit\u001b[0;34m(X_i, y_i, ridge, d_thr)\u001b[0m\n\u001b[1;32m    131\u001b[0m X_ip \u001b[38;5;241m=\u001b[39m X_i \u001b[38;5;241m@\u001b[39m U[:, :d_fit]\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Fit the output based on the projection\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[43mridge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m r_sq_p \u001b[38;5;241m=\u001b[39m ridge\u001b[38;5;241m.\u001b[39mscore(X_ip, y_i)\n\u001b[1;32m    135\u001b[0m d_fits\u001b[38;5;241m.\u001b[39mappend(d_fit)\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2380\u001b[0m, in \u001b[0;36mRidgeCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2350\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2352\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Ridge regression model with cv.\u001b[39;00m\n\u001b[1;32m   2353\u001b[0m \n\u001b[1;32m   2354\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[38;5;124;03m    the validation score.\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2380\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2182\u001b[0m, in \u001b[0;36m_BaseRidgeCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2173\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m _RidgeGCV(\n\u001b[1;32m   2174\u001b[0m         alphas,\n\u001b[1;32m   2175\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         alpha_per_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_per_target,\n\u001b[1;32m   2181\u001b[0m     )\n\u001b[0;32m-> 2182\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39malpha_\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2020\u001b[0m, in \u001b[0;36m_RidgeGCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2017\u001b[0m best_coef, best_score, best_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas)):\n\u001b[0;32m-> 2020\u001b[0m     G_inverse_diag, c \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqrt_sw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecomposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m   2022\u001b[0m         squared_errors \u001b[38;5;241m=\u001b[39m (c \u001b[38;5;241m/\u001b[39m G_inverse_diag) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1934\u001b[0m, in \u001b[0;36m_RidgeGCV._solve_svd_design_matrix\u001b[0;34m(self, alpha, y, sqrt_sw, X_mean, singvals_sq, U, UT_y)\u001b[0m\n\u001b[1;32m   1932\u001b[0m     w[intercept_dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1933\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(U, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diag_dot(w, UT_y)) \u001b[38;5;241m+\u001b[39m (alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m y\n\u001b[0;32m-> 1934\u001b[0m G_inverse_diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decomp_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# handle case where y is 2-d\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     G_inverse_diag \u001b[38;5;241m=\u001b[39m G_inverse_diag[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1634\u001b[0m, in \u001b[0;36m_RidgeGCV._decomp_diag\u001b[0;34m(v_prime, Q)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decomp_diag\u001b[39m(v_prime, Q):\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;66;03m# compute diagonal of the matrix: dot(Q, dot(diag(v_prime), Q^T))\u001b[39;00m\n\u001b[0;32m-> 1634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mv_prime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv/lib/python3.10/site-packages/numpy/core/_methods.py:46\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute results\n",
    "\n",
    "dataset_supers = [\n",
    "    \"bci-golub_2018\",\n",
    "    \"bci-hennig_2018\",\n",
    "    \"bci-degenhart_2020\",\n",
    "    \"russo_2018_1\", \n",
    "    \"russo_2018_2\", \n",
    "    \"nlb-mc_maze_large\",\n",
    "    \"nlb-mc_rtt\",\n",
    "    # \"nlb-mc_maze_small\",\n",
    "]\n",
    "\n",
    "# Decide whether to compute everything or only a part.\n",
    "compute_mods = \"vel_only\"\n",
    "# compute_mods = \"all\"\n",
    "\n",
    "if compute_mods == \"vel_only\":\n",
    "    ba_learning = [\"before\"]\n",
    "elif compute_mods == \"all\":\n",
    "    ba_learning = [\"before\", \"after\"]\n",
    "    \n",
    "\n",
    "results = {}\n",
    "time0 = time.time()\n",
    "for dataset_super in dataset_supers:\n",
    "    if dataset_super.startswith('bci'):\n",
    "        _, dataset = dataset_super.split('-')\n",
    "        if dataset in ['golub_2018', 'hennig_2018']:\n",
    "            if dataset == 'golub_2018':\n",
    "                output_dict, hids_dict = load_golub_2018(0)\n",
    "            if dataset == 'hennig_2018':\n",
    "                output_dict, hids_dict = load_hennig_2018(0)\n",
    "            # Before and after\n",
    "            for key in ba_learning:\n",
    "                ds_name = dataset_super + '-' + key\n",
    "                print(ds_name)\n",
    "                output = output_dict[key]\n",
    "                hids = hids_dict[key]\n",
    "                results[ds_name] = comp_ridge(hids, output)\n",
    "        elif dataset == \"degenhart_2020\":\n",
    "            key = 'before'\n",
    "            ds_name = dataset_super + '-' + key\n",
    "            print(ds_name)\n",
    "            output, hids = load_degenhart_2020(fit_kalman=False)\n",
    "            results[ds_name] = comp_ridge(hids, output)\n",
    "\n",
    "    if dataset_super.startswith('russo'):\n",
    "        i_monkey = np.where(dataset_super[-1] == np.array(list('12')))[0][0]\n",
    "        file_name = [\"Cousteau_tt.mat\", \"Drake_tt.mat\"][i_monkey]\n",
    "        output_dict, hids_dict = load_russo_2018(file_name, subs_step=5)\n",
    "        # Output modalities\n",
    "        output_mods = [\"emg\", \"hand_pos\", \"hand_vel\", \"hand_acc\"]\n",
    "        if compute_mods == \"vel_only\":\n",
    "            output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "        elif compute_mods == \"all\":\n",
    "            pass\n",
    "        for key in output_mods:\n",
    "            ds_name = dataset_super + '-' + key\n",
    "            print(ds_name)\n",
    "            output = output_dict[key]\n",
    "            hids = hids_dict[key]\n",
    "            results[ds_name] = comp_ridge(hids, output)\n",
    "\n",
    "    if dataset_super.startswith('nlb'):\n",
    "        if dataset_super.split('-')[1].startswith(\"mc_maze\"):\n",
    "            output_dict, hids_dict = load_nlb_maze(dataset_super)\n",
    "            # Output modalities\n",
    "            output_mods = [\"hand_pos\", \"hand_vel\", \"hand_acc\"]\n",
    "            if compute_mods == \"vel_only\":\n",
    "                output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "            elif compute_mods == \"all\":\n",
    "                pass\n",
    "            # Single trials or averages?\n",
    "            single_or_tcas = [\"single\", \"tca\"]\n",
    "            for output_mod in output_mods:\n",
    "                for single_or_tca in single_or_tcas:\n",
    "                    ds_name = dataset_super + '-' + output_mod + '-' + single_or_tca\n",
    "                    print(ds_name)\n",
    "                    key = output_mod\n",
    "                    if single_or_tca == 'tca':\n",
    "                        key += \"_tca\"\n",
    "                    output = output_dict[key]\n",
    "                    hids = hids_dict[key]\n",
    "                    results[ds_name] = comp_ridge(hids, output)\n",
    "\n",
    "        if dataset_super.split('-')[1].startswith(\"mc_rtt\"):\n",
    "            output_dict, hids_dict = load_nlb_rtt(dataset_super)\n",
    "            output_mods = [\"finger_pos\", \"finger_vel\", \"finger_acc\"]\n",
    "            if compute_mods == \"vel_only\":\n",
    "                output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "            elif compute_mods == \"all\":\n",
    "                pass\n",
    "            for key in output_mods:\n",
    "                ds_name = dataset_super + '-' + key\n",
    "                print(ds_name)\n",
    "                output = output_dict[key]\n",
    "                hids = hids_dict[key]\n",
    "                results[ds_name] = comp_ridge(hids, output)\n",
    "\n",
    "print(\"Took %.3f sec.\" % (time.time() - time0))\n",
    "\n",
    "# Save data\n",
    "res = [\n",
    "    dataset_supers, \n",
    "    results,\n",
    "]\n",
    "# Save data\n",
    "file_name = \"data_corr_dims.pkl\"\n",
    "data_file = os.path.join(data_path, file_name)\n",
    "with open(data_file, 'wb') as handle:\n",
    "    pickle.dump(res, handle)\n",
    "print('Saved to ', data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85101dad-5624-4373-9018-d70c4cba50c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b39c3a-1335-48dd-a6b1-a910ddd0921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1d7e2-801c-4252-8b1c-1509808289a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715d021-01c6-4e6f-96e1-1f87c6372da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144cd06-d8e8-48ad-8488-3fc27342df71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
