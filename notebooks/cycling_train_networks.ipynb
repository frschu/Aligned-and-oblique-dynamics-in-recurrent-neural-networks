{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cpu.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "use_cuda = True\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Use cuda.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Use cpu.\")\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# Custom\n",
    "from helpers import copy_sd, res_to_cpu\n",
    "from rnn_model_dt import RNN_Net\n",
    "from task_generators import cycling as task_generator\n",
    "task_name = \"cycling\"\n",
    "\n",
    "# Data path\n",
    "from specs import data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_samples = 1\n",
    "\n",
    "# Network\n",
    "dim_in = 2\n",
    "dim_hid = 256\n",
    "dim_out = 2\n",
    "n_layers = 2\n",
    "bias = False\n",
    "train_in = False\n",
    "train_hid = True\n",
    "train_out = False\n",
    "train_layers = [train_in, train_hid, train_out]\n",
    "nonlin = torch.nn.Tanh()\n",
    "gaussian_init = True\n",
    "h_0_std = 1.\n",
    "dt = 0.2\n",
    "rec_step_dt = 1\n",
    "mask_step_dt = 5\n",
    "batch_size = 32\n",
    "t_dec = 71 \n",
    "freq = 0.1\n",
    "task_params = dict(\n",
    "    rec_step_dt=rec_step_dt,\n",
    "    mask_step_dt=mask_step_dt,\n",
    "    t_dec=t_dec,\n",
    "    freq=freq,\n",
    ")\n",
    "# Noise on input, h_0, and hidden states\n",
    "noise_input_std = 0.0\n",
    "noise_init_std = 1.0\n",
    "noise_hid_std = 0.2\n",
    "\n",
    "# Joint scenarios\n",
    "out_scales = ['large', 'small']\n",
    "gs = [1.5, 1.5]\n",
    "lr0s = [0.1, 0.1] \n",
    "n_sce = len(out_scales)\n",
    "opt_gens = [Adam]*n_sce\n",
    "n_mi = n_samples, n_sce\n",
    "\n",
    "n_steps = 5000\n",
    "n_rec_steps = n_steps // 50\n",
    "\n",
    "# Task generators and fixed eval task\n",
    "task_gen = task_generator(dim_in, dim_out, dt, **task_params)\n",
    "task_params_ev = deepcopy(task_params)\n",
    "task_params_ev[\"t_max\"] = t_dec * 3\n",
    "task_gen_ev = task_generator(dim_in, dim_out, dt, **task_params_ev)\n",
    "ts_ev, input_ev, target_ev, mask_ev = task_gen_ev(batch_size)\n",
    "noise_input_ev = noise_input_std * np.float32(np.random.randn(*input_ev.shape)) / np.sqrt(dt)\n",
    "noise_init_ev = noise_init_std * np.float32(np.random.randn(n_layers-1, batch_size, dim_hid)) \n",
    "n_t_ev = len(ts_ev)\n",
    "task_ev = ts_ev, input_ev, target_ev, mask_ev, noise_input_ev, noise_init_ev\n",
    "\n",
    "##############################################################################\n",
    "# Train networks\n",
    "# Loss\n",
    "loss_crit = torch.nn.MSELoss()\n",
    "\n",
    "# Results arrays\n",
    "n_if = 2\n",
    "n_ifn = 4\n",
    "steps = torch.arange(n_steps)\n",
    "loss_all = torch.zeros((*n_mi, n_steps))\n",
    "output_all = torch.zeros((n_ifn, *n_mi, batch_size, n_t_ev, dim_out))\n",
    "hids_all = 0#torch.zeros((n_ifn, *n_mi, batch_size, n_t_ev, dim_hid))\n",
    "h_0_all = torch.zeros((*n_mi, n_layers-1, batch_size, dim_hid))\n",
    "sd_if_all = np.zeros((n_if, *n_mi), dtype=object)\n",
    "w_in_norm_all = torch.zeros((*n_mi, n_steps))\n",
    "w_rec_norm_all = torch.zeros((*n_mi, n_steps))\n",
    "w_out_norm_all = torch.zeros((*n_mi, n_steps))\n",
    "dw_out_norm_all = torch.zeros((*n_mi, n_steps))\n",
    "dw_rec_norm_all = torch.zeros((*n_mi, n_steps))\n",
    "\n",
    "rec_step_width = n_steps // n_rec_steps\n",
    "rec_steps = torch.arange(0, n_steps, rec_step_width)\n",
    "loss_avg_all = torch.zeros((*n_mi, n_rec_steps))\n",
    "\n",
    "# PCA of activity for power spectra\n",
    "n_comp = 10\n",
    "# Discard initial transient for PCA\n",
    "t_pc_min = 10\n",
    "n_t_pc_min = int(t_pc_min / (dt * rec_step_dt))\n",
    "n_t_pc = n_t_ev - n_t_pc_min\n",
    "# Frequencies for FFT\n",
    "dt_rec = rec_step_dt * dt\n",
    "freqs = np.fft.fftfreq(n_t_pc, dt_rec)\n",
    "mf = freqs >= 0\n",
    "freqs = freqs[mf]\n",
    "n_f = len(freqs)\n",
    "h_proj_all = np.zeros((*n_mi, n_rec_steps, batch_size, n_t_pc, n_comp))\n",
    "ps_all = np.zeros((n_samples, n_sce, n_rec_steps, batch_size, n_f, n_comp))\n",
    "\n",
    "# Task to device\n",
    "to_dev = lambda arr: (torch.from_numpy(arr).to(device)\n",
    "                       if type(arr) == np.ndarray else arr.to(device))\n",
    "ts_ev, input_ev, target_ev, mask_ev, noise_input_ev, noise_init_ev = [to_dev(arr) for arr in task_ev]\n",
    "\n",
    "# Run\n",
    "time0 = time.time()\n",
    "for mi in np.ndindex(*n_mi):\n",
    "    i_s, i_sce = mi\n",
    "    out_scale = out_scales[i_sce]\n",
    "    g = gs[i_sce]\n",
    "    lr0 = lr0s[i_sce]\n",
    "    opt_gen = opt_gens[i_sce]\n",
    "    # Network instance\n",
    "    net = RNN_Net(dim_in, dim_hid, dim_out, n_layers, nonlin, bias, out_scale, g, gaussian_init, \n",
    "                  dt, rec_step_dt, train_layers)\n",
    "    net.to(device)\n",
    "    # Initial state: the same for each batch!\n",
    "    h_0 = h_0_std * torch.randn((n_layers - 1, 1, dim_hid), device=device)\n",
    "    h_0 = torch.tile(h_0, (1, batch_size, 1))\n",
    "    h_0_all[mi] = h_0.detach()\n",
    "\n",
    "    # Optimizer\n",
    "    if opt_gen == torch.optim.Adam:\n",
    "        lr = lr0 / dim_hid\n",
    "    else:\n",
    "        lr = lr0\n",
    "    opt = opt_gen(net.parameters(), lr=lr)\n",
    "\n",
    "    # Save before training\n",
    "    sd_if_all[0][mi]= copy_sd(net.state_dict)\n",
    "    with torch.no_grad():\n",
    "        # With noise\n",
    "        output, hids = net.forward_hid(input_ev + noise_input_ev, \n",
    "                                       h_0 + noise_init_ev, \n",
    "                                       noise_hid_std, last_time=False)\n",
    "        output_all[0][mi] = output\n",
    "        # No noise\n",
    "        output, hids = net.forward_hid(input_ev, h_0, last_time=False)\n",
    "        output_all[2][mi] = output\n",
    "\n",
    "    # Train\n",
    "    for step in tqdm(range(n_steps)):\n",
    "        # Record\n",
    "        # 500 iterations took 24 sec each without recording; 32 sec with\n",
    "        with torch.no_grad():\n",
    "            # Norm of weight changes\n",
    "            w_in = net.rnn.weight_ih_l0\n",
    "            w_rec = net.rnn.weight_hh_l0\n",
    "            w_out = net.decoder.weight\n",
    "            w_in_norm_all[mi][step] = torch.linalg.norm(w_in).item()\n",
    "            w_rec_norm_all[mi][step] = torch.linalg.norm(w_rec).item()\n",
    "            w_out_norm_all[mi][step] = torch.linalg.norm(w_out).item()\n",
    "            dw_out_norm_all[mi][step] = torch.linalg.norm(\n",
    "                w_out - sd_if_all[0][mi][\"decoder.weight\"]).item()\n",
    "            dw_rec_norm_all[mi][step] = torch.linalg.norm(\n",
    "                w_rec - sd_if_all[0][mi][\"rnn.weight_hh_l0\"]).item()\n",
    "            if step % rec_step_width == 0:\n",
    "                rec_step = step // rec_step_width\n",
    "                output, hids = net.forward_hid(input_ev + noise_input_ev, \n",
    "                                               h_0 + noise_init_ev, \n",
    "                                               noise_hid_std, last_time=False)\n",
    "                # Loss for the batch-averaged output. This is a bit tricky, because the targe depends on i_b\n",
    "                diffs_avg = (output - target_ev).mean(0)[mask_ev[0]]\n",
    "                loss = loss_crit(diffs_avg, 0. * diffs_avg)\n",
    "                loss_avg_all[mi][rec_step] = loss\n",
    "                \n",
    "                # First components of PCA\n",
    "                h = hids[0, :, n_t_pc_min:].reshape(batch_size * n_t_pc, dim_hid).cpu()\n",
    "                pca = PCA(n_comp)\n",
    "                pca.fit(h)\n",
    "                h_proj = pca.transform(h).reshape(batch_size, n_t_pc, n_comp)\n",
    "                # Power spectra via FFT\n",
    "                ps = np.abs(np.fft.fft(h_proj, axis=-2)[:, mf, :])**2\n",
    "                h_proj_all[mi][rec_step] = h_proj\n",
    "                ps_all[mi][rec_step] = ps\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # Draw an independent task each time\n",
    "        task = task_gen(batch_size)\n",
    "        _, input, target, mask = [to_dev(arr) for arr in task]\n",
    "        # Draw independent input noise every time!\n",
    "        noise_init = noise_init_std * torch.randn_like(h_0)\n",
    "        noise_input = noise_input_std * torch.randn_like(input) / np.sqrt(dt)\n",
    "        output = net(input + noise_input, h_0 + noise_init, noise_hid_std)\n",
    "        loss = loss_crit(output[mask], target[mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss_all[mi][step] = loss.item()\n",
    "\n",
    "    # Save after training\n",
    "    sd_if_all[1][mi] = copy_sd(net.state_dict)\n",
    "    with torch.no_grad():\n",
    "        # With noise\n",
    "        output, hids = net.forward_hid(input_ev + noise_input_ev, \n",
    "                                       h_0 + noise_init_ev, \n",
    "                                       noise_hid_std, last_time=False)\n",
    "        output_all[1][mi] = output\n",
    "        # No noise\n",
    "        output, hids = net.forward_hid(input_ev, h_0, last_time=False)\n",
    "        output_all[3][mi] = output\n",
    "        # hids_all[3][mi] = hids[0]\n",
    "print(\"Took %.1f sec.\" % (time.time() - time0))\n",
    "\n",
    "#######################################################################################\n",
    "# Move everything to cpu!\n",
    "res_list = [sd_if_all]\n",
    "res_to_cpu(res_list)\n",
    "\n",
    "# Save\n",
    "save_data = True\n",
    "if save_data:\n",
    "    res = [\n",
    "        n_steps, n_samples, gs, out_scales, n_sce, opt_gens, lr0s, n_mi, dim_hid, dim_in, dim_out, \n",
    "        dt, rec_step_dt, n_layers, bias, train_in, train_hid, train_out, train_layers, nonlin, \n",
    "        gaussian_init, h_0_std, noise_input_std, noise_init_std, noise_hid_std, batch_size, \n",
    "        task_params, task_params_ev, n_t_ev, task_ev, n_if, n_ifn, steps, \n",
    "        loss_all, output_all, hids_all, h_0_all, sd_if_all, \n",
    "        n_rec_steps, rec_step_width, rec_steps, loss_avg_all, \n",
    "        w_in_norm_all, w_rec_norm_all, w_out_norm_all,\n",
    "        dw_out_norm_all, dw_rec_norm_all, \n",
    "        h_proj_all, ps_all,\n",
    "    ]\n",
    "    # Save data\n",
    "    file_name = \"cycling\" + \"_n_%d_train_rec_only\" % dim_hid\n",
    "    file_name = \"_\".join(file_name.split('.'))\n",
    "    data_file = os.path.join(data_path, file_name + \".pkl\")\n",
    "    with open(data_file, 'wb') as handle:\n",
    "        pickle.dump(res, handle)\n",
    "    print('Saved to ', data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
