{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf8d058-5442-4b04-825c-8231b3b8741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from numpy.linalg import norm, svd\n",
    "from helpers import comp_pr\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Data path\n",
    "from specs import data_path, rng\n",
    "\n",
    "from data_loaders import (\n",
    "    load_golub_2018, load_hennig_2018, load_degenhart_2020, load_russo_2018, load_nlb_maze, load_nlb_rtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62bd943-97b0-4501-bfdd-077b81a19442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_corr(X, w_out):\n",
    "    \"\"\" Correlation between states and output weights.\n",
    "    With population average at each time point subtracted.\n",
    "    \"\"\"\n",
    "    return norm(X @ w_out.T) / (norm(X) * norm(w_out))\n",
    "\n",
    "def comp_ridge(hids, output, comp_neuron_subs=False, d_thr=0.9, ):\n",
    "    X = hids.astype(float)\n",
    "    y = output\n",
    "    n_samples, dim_hid = X.shape\n",
    "    # Center along time\n",
    "    X = X - X.mean(0)\n",
    "    y = y - y.mean(0)\n",
    "    # # Z-score along time\n",
    "    # X = (X - X.mean(0)) / X.std(0)\n",
    "    # y = (y - y.mean(0)) / y.std(0)\n",
    "    \n",
    "    # Ridge regression with cross validation. \n",
    "    alpha_range = np.logspace(-3, 6, 20)\n",
    "    ridge = RidgeCV(alphas=alpha_range)\n",
    "    ridge.fit(X, y)\n",
    "    r_sq = ridge.score(X, y)\n",
    "    ridge_alpha = ridge.alpha_  # Save for documentation\n",
    "    w_out = ridge.coef_\n",
    "    \n",
    "    # Correlation between output weights and hidden states\n",
    "    corr_w_x = comp_corr(X, w_out)\n",
    "    \n",
    "    # Participation ratio\n",
    "    pr = comp_pr(X)\n",
    "    \n",
    "    # Compute dimensions of data and necessary to fit\n",
    "    d_var, d_fit_rel, d_fits, r_sq_ps = comp_dim_var_fit(X, y, ridge, d_thr)\n",
    "    # Ratio between relative dimensions\n",
    "    ratio_d_fit_var_rel = d_fit_rel / d_var\n",
    "    \n",
    "    res = {\n",
    "        \"r_sq\": r_sq, \n",
    "        \"ridge_alpha\": ridge_alpha, \n",
    "        \"corr_w_x\": corr_w_x, \n",
    "        \"pr\": pr, \n",
    "        \"n_samples\": n_samples, \n",
    "        \"dim_hid\": dim_hid, \n",
    "        \"d_var\": d_var, \n",
    "        \"d_fit_rel\": d_fit_rel, \n",
    "        \"ratio_d_fit_var_rel\": ratio_d_fit_var_rel,\n",
    "        \"w_out\": w_out,\n",
    "    }\n",
    "    \n",
    "    ### Fits on subsets\n",
    "    lbls_res_t = [\n",
    "        \"r_sq\", \n",
    "        \"ridge_alpha\", \n",
    "        \"corr_w_x\", \n",
    "        \"pr\", \n",
    "        \"d_var\", \n",
    "        \"d_fit_rel\", \n",
    "        \"ratio_d_fit_var_rel\", \n",
    "               ]\n",
    "    # Fit on subsamples in time points\n",
    "    n_fit_t = 20\n",
    "    frac_n_t = 1/2\n",
    "    n_subs_t = int(n_samples * frac_n_t)\n",
    "    # Results\n",
    "    res_subs_t = np.zeros((len(lbls_res_t), n_fit_t))\n",
    "    for i_fit in tqdm(range(n_fit_t)):\n",
    "        idx_s = rng.choice(n_samples, n_subs_t, replace=False)\n",
    "        X_s, y_s = X[idx_s], y[idx_s]\n",
    "        ridge.fit(X_s, y_s)\n",
    "        w_out_s = ridge.coef_\n",
    "        res_subs_t[0, i_fit] = ridge.score(X_s, y_s)\n",
    "        res_subs_t[1, i_fit] = ridge.alpha_\n",
    "        res_subs_t[2, i_fit] = comp_corr(X_s, w_out_s)\n",
    "        res_subs_t[3, i_fit] = comp_pr(X_s)\n",
    "        \n",
    "        # Compute dimensions of data and necessary to fit\n",
    "        d_var, d_fit_rel, d_fits, r_sq_ps = comp_dim_var_fit(X_s, y_s, ridge, d_thr)\n",
    "        ratio_d_fit_var_rel = d_fit_rel / d_var\n",
    "        res_subs_t[4:7, i_fit] = d_var, d_fit_rel, ratio_d_fit_var_rel,\n",
    "    # Save as dict\n",
    "    res_subs_t = {lbls_res_t[i]: res_sub for i, res_sub in enumerate(res_subs_t)}\n",
    "    \n",
    "    # Fit on subsets of neurons\n",
    "    # Number of subsets\n",
    "    n_fit_n = 20\n",
    "    # Number of neurons\n",
    "    frac_dim_hids = np.linspace(0.1, 1., 10)\n",
    "    dim_hid_subs = np.int_(dim_hid * frac_dim_hids)\n",
    "    n_dim_hid = len(dim_hid_subs)\n",
    "    # Results\n",
    "    lbls_res_n = [\"r_sq\", \"ridge_alpha\", \"corr_w_x\", \"pr\",\n",
    "               ]\n",
    "    res_subs_n = np.zeros((len(lbls_res_n), n_fit_n, n_dim_hid))\n",
    "    if comp_neuron_subs:\n",
    "        for i_fit in tqdm(range(n_fit_n)):\n",
    "            for i_n in range(n_dim_hid):\n",
    "                dim_hid_i = dim_hid_subs[i_n]\n",
    "                idx_n = rng.choice(dim_hid, dim_hid_i, replace=False)\n",
    "                X_n = X[:, idx_n]\n",
    "                ridge.fit(X_n, y)\n",
    "                w_out_s = ridge.coef_\n",
    "                res_subs_n[0, i_fit, i_n] = ridge.score(X_n, y)\n",
    "                res_subs_n[1, i_fit, i_n] = ridge.alpha_\n",
    "                res_subs_n[2, i_fit, i_n] = comp_corr(X_n, w_out_s)\n",
    "                res_subs_n[3, i_fit, i_n] = comp_pr(X_n)\n",
    "\n",
    "    # Save as dict\n",
    "    res_subs_n = {lbls_res_n[i]: res_sub for i, res_sub in enumerate(res_subs_n)}\n",
    "\n",
    "    return res, res_subs_t, res_subs_n\n",
    "\n",
    "def comp_dim_var_fit(X_i, y_i, ridge, d_thr):\n",
    "    # Compare variance explained with the ability to fit based on the leading components\n",
    "    dim_hid = X_i.shape[1]\n",
    "\n",
    "    # Use SVD instead of PCA (adds one mode if not z-scored)\n",
    "    U, S, _ = svd(X_i.T, full_matrices=False)\n",
    "    # Dimension of data\n",
    "    cevr = (S**2).cumsum() / (S**2).sum()\n",
    "    i_thr = np.where(cevr > d_thr)[0]\n",
    "    d_var = i_thr[0] + 1\n",
    "    \n",
    "    # Fit on full dataset first\n",
    "    ridge.fit(X_i, y_i)\n",
    "    r_sq_full = ridge.score(X_i, y_i)\n",
    "    \n",
    "    # Fit based on first k PCs of X. \n",
    "    d_fits = []\n",
    "    r_sq_ps = []\n",
    "    d_fit = 0\n",
    "    while True:\n",
    "        d_fit += 1\n",
    "        if d_fit > dim_hid:\n",
    "            break\n",
    "        # Projection of X onto leading modes\n",
    "        X_ip = X_i @ U[:, :d_fit]\n",
    "        # Fit the output based on the projection\n",
    "        ridge.fit(X_ip, y_i)\n",
    "        r_sq_p = ridge.score(X_ip, y_i)\n",
    "        d_fits.append(d_fit)\n",
    "        r_sq_ps.append(r_sq_p)\n",
    "        if r_sq_p > r_sq_full * d_thr:\n",
    "            d_fit_rel = d_fit\n",
    "            break\n",
    "\n",
    "    return d_var, d_fit_rel, d_fits, r_sq_ps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437e04e3-9d18-4dce-a1d7-c2b49c7c2e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci-golub_2018-before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.67it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:13<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci-hennig_2018-before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:06<00:00,  3.10it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci-degenhart_2020-before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.02it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:47<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_1-emg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:10<00:00,  1.87it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_1-hand_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:13<00:00,  1.49it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_1-hand_vel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:11<00:00,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_1-hand_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.57it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:41<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_2-emg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.56it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_2-hand_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:10<00:00,  1.99it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:40<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_2-hand_vel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.65it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:41<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russo_2018_2-hand_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:14<00:00,  1.35it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_pos-single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:17<00:00,  1.13it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:37<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_pos-tca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:03<00:00,  5.71it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:13<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_vel-single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:20<00:00,  1.02s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:39<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_vel-tca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:04<00:00,  4.22it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:14<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_acc-single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [01:01<00:00,  3.05s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:39<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_maze_large-hand_acc-tca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:08<00:00,  2.32it/s]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:15<00:00,  1.28it/s]\n",
      "/home/friedrich/.virtualenvs/venv/lib/python3.10/site-packages/pandas/core/generic.py:4150: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_rtt-finger_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [01:08<00:00,  3.40s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:37<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_rtt-finger_vel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:24<00:00,  1.21s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlb-mc_rtt-finger_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:59<00:00,  2.95s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [00:37<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1142.214 sec.\n",
      "Saved to  ../data/data_corr_dims.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute results\n",
    "\n",
    "from importlib import reload\n",
    "import data_loaders; reload(data_loaders)\n",
    "from data_loaders import (\n",
    "    load_golub_2018, load_hennig_2018, load_degenhart_2020, load_russo_2018, load_nlb_maze, load_nlb_rtt)\n",
    "\n",
    "dataset_supers = [\n",
    "    \"bci-golub_2018\",\n",
    "    \"bci-hennig_2018\",\n",
    "    \"bci-degenhart_2020\",\n",
    "    \"russo_2018_1\", \n",
    "    \"russo_2018_2\", \n",
    "    \"nlb-mc_maze_large\",\n",
    "    \"nlb-mc_rtt\",\n",
    "    # \"nlb-mc_maze_small\",\n",
    "]\n",
    "\n",
    "# Decide whether to compute everything or only a part.\n",
    "# compute_mods = \"vel_only\"\n",
    "compute_mods = \"all\"\n",
    "\n",
    "if compute_mods == \"vel_only\":\n",
    "    ba_learning = [\"before\"]\n",
    "elif compute_mods == \"all\":\n",
    "    # ba_learning = [\"before\", \"after\"]\n",
    "    ba_learning = [\"before\"]\n",
    "    \n",
    "# Compute subsets of neurons? \n",
    "comp_neuron_subs = True #compute_mods == \"vel_only\"\n",
    "\n",
    "results = {}\n",
    "time0 = time.time()\n",
    "for dataset_super in dataset_supers[:]:\n",
    "    if dataset_super.startswith('bci'):\n",
    "        _, dataset = dataset_super.split('-')\n",
    "        if dataset in ['golub_2018', 'hennig_2018']:\n",
    "            if dataset == 'golub_2018':\n",
    "                output_dict, hids_dict = load_golub_2018(0)\n",
    "            if dataset == 'hennig_2018':\n",
    "                output_dict, hids_dict = load_hennig_2018(0)\n",
    "            # Before and after\n",
    "            for key in ba_learning:\n",
    "                ds_name = dataset_super + '-' + key\n",
    "                print(ds_name)\n",
    "                output = output_dict[key]\n",
    "                hids = hids_dict[key]\n",
    "                results[ds_name] = comp_ridge(hids, output, comp_neuron_subs)\n",
    "        elif dataset == \"degenhart_2020\":\n",
    "            key = 'before'\n",
    "            ds_name = dataset_super + '-' + key\n",
    "            print(ds_name)\n",
    "            output, hids = load_degenhart_2020(fit_kalman=False)\n",
    "            results[ds_name] = comp_ridge(hids, output, comp_neuron_subs)\n",
    "\n",
    "    if dataset_super.startswith('russo'):\n",
    "        i_monkey = np.where(dataset_super[-1] == np.array(list('12')))[0][0]\n",
    "        file_name = [\"Cousteau_tt.mat\", \"Drake_tt.mat\"][i_monkey]\n",
    "        output_dict, hids_dict = load_russo_2018(file_name, subs_step=5)\n",
    "        # Output modalities\n",
    "        output_mods = [\"emg\", \"hand_pos\", \"hand_vel\", \"hand_acc\"]\n",
    "        if compute_mods == \"vel_only\":\n",
    "            output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "        elif compute_mods == \"all\":\n",
    "            pass\n",
    "        for key in output_mods:\n",
    "            ds_name = dataset_super + '-' + key\n",
    "            print(ds_name)\n",
    "            output = output_dict[key]\n",
    "            hids = hids_dict[key]\n",
    "            results[ds_name] = comp_ridge(hids, output, comp_neuron_subs)\n",
    "\n",
    "    if dataset_super.startswith('nlb'):\n",
    "        if dataset_super.split('-')[1].startswith(\"mc_maze\"):\n",
    "            output_dict, hids_dict = load_nlb_maze(dataset_super)\n",
    "            # Output modalities\n",
    "            output_mods = [\"hand_pos\", \"hand_vel\", \"hand_acc\"]\n",
    "            if compute_mods == \"vel_only\":\n",
    "                output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "            elif compute_mods == \"all\":\n",
    "                pass\n",
    "            # Single trials or averages?\n",
    "            single_or_tcas = [\"single\", \"tca\"]\n",
    "            for output_mod in output_mods:\n",
    "                for single_or_tca in single_or_tcas:\n",
    "                    ds_name = dataset_super + '-' + output_mod + '-' + single_or_tca\n",
    "                    print(ds_name)\n",
    "                    key = output_mod\n",
    "                    if single_or_tca == 'tca':\n",
    "                        key += \"_tca\"\n",
    "                    output = output_dict[key]\n",
    "                    hids = hids_dict[key]\n",
    "                    results[ds_name] = comp_ridge(hids, output, comp_neuron_subs)\n",
    "\n",
    "        if dataset_super.split('-')[1].startswith(\"mc_rtt\"):\n",
    "            output_dict, hids_dict = load_nlb_rtt(dataset_super)\n",
    "            output_mods = [\"finger_pos\", \"finger_vel\", \"finger_acc\"]\n",
    "            if compute_mods == \"vel_only\":\n",
    "                output_mods = [om for om in output_mods if om.split('_')[-1] == \"vel\"]\n",
    "            elif compute_mods == \"all\":\n",
    "                pass\n",
    "            for key in output_mods:\n",
    "                ds_name = dataset_super + '-' + key\n",
    "                print(ds_name)\n",
    "                output = output_dict[key]\n",
    "                hids = hids_dict[key]\n",
    "                results[ds_name] = comp_ridge(hids, output, comp_neuron_subs)\n",
    "\n",
    "print(\"Took %.3f sec.\" % (time.time() - time0))\n",
    "\n",
    "# Save data\n",
    "res = [\n",
    "    dataset_supers, \n",
    "    results,\n",
    "]\n",
    "# Save data\n",
    "file_name = \"data_corr_dims.pkl\"\n",
    "if compute_mods == \"vel_only\":\n",
    "    file_name = \"data_corr_dims_vel_only.pkl\"\n",
    "data_file = os.path.join(data_path, file_name)\n",
    "with open(data_file, 'wb') as handle:\n",
    "    pickle.dump(res, handle)\n",
    "print('Saved to ', data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c671f2-538e-4625-85eb-a444ce076ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715d021-01c6-4e6f-96e1-1f87c6372da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144cd06-d8e8-48ad-8488-3fc27342df71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
